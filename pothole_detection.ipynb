{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths for your dataset\n",
    "base_path = 'C:\\\\Users\\\\Srikrishna\\\\Documents\\\\GitHub\\\\Sem_4\\\\Robotics-MFC-S4-D12\\\\pothole_image_data'\n",
    "normal_path = os.path.join(base_path, 'normal')\n",
    "potholes_path = os.path.join(base_path, 'potholes')\n",
    "\n",
    "# Create train and val directories under pothole_image_data\n",
    "train_images_path = os.path.join(base_path, 'train', 'images')\n",
    "train_labels_path = os.path.join(base_path, 'train', 'labels')\n",
    "val_images_path = os.path.join(base_path, 'val', 'images')\n",
    "val_labels_path = os.path.join(base_path, 'val', 'labels')\n",
    "\n",
    "# Create directories if they don't exist\n",
    "for path in [train_images_path, train_labels_path, val_images_path, val_labels_path]:\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "# Function to split dataset into train and val\n",
    "def split_dataset(normal_path, potholes_path, train_ratio=0.8):\n",
    "    # Get all normal and pothole image paths\n",
    "    normal_images = [os.path.join(normal_path, f) for f in os.listdir(normal_path) if f.endswith('.jpg')]\n",
    "    pothole_images = [os.path.join(potholes_path, f) for f in os.listdir(potholes_path) if f.endswith('.jpg')]\n",
    "    \n",
    "    # Split normal images\n",
    "    normal_train, normal_val = train_test_split(normal_images, train_size=train_ratio, random_state=42)\n",
    "    # Split pothole images\n",
    "    pothole_train, pothole_val = train_test_split(pothole_images, train_size=train_ratio, random_state=42)\n",
    "    \n",
    "    # Copy images to train and val directories\n",
    "    for img_path in normal_train:\n",
    "        shutil.copy(img_path, os.path.join(train_images_path, os.path.basename(img_path)))\n",
    "        # Create empty label file for normal (no potholes)\n",
    "        label_path = os.path.join(train_labels_path, os.path.splitext(os.path.basename(img_path))[0] + '.txt')\n",
    "        with open(label_path, 'w') as f:\n",
    "            pass  # Empty file indicates no potholes\n",
    "    \n",
    "    for img_path in normal_val:\n",
    "        shutil.copy(img_path, os.path.join(val_images_path, os.path.basename(img_path)))\n",
    "        label_path = os.path.join(val_labels_path, os.path.splitext(os.path.basename(img_path))[0] + '.txt')\n",
    "        with open(label_path, 'w') as f:\n",
    "            pass  # Empty file indicates no potholes\n",
    "    \n",
    "    for img_path in pothole_train:\n",
    "        shutil.copy(img_path, os.path.join(train_images_path, os.path.basename(img_path)))\n",
    "        # You need to provide or generate YOLO annotations for potholes\n",
    "        label_path = os.path.join(train_labels_path, os.path.splitext(os.path.basename(img_path))[0] + '.txt')\n",
    "        # Placeholder for pothole annotation (replace with actual annotations)\n",
    "        # Example: '0 0.5 0.5 0.2 0.2' for a pothole centered with width/height 20% of image\n",
    "        # You must create these manually or using a tool like LabelImg/Roboflow\n",
    "        with open(label_path, 'w') as f:\n",
    "            f.write('0 0.5 0.5 0.2 0.2')  # Example, replace with real annotations\n",
    "    \n",
    "    for img_path in pothole_val:\n",
    "        shutil.copy(img_path, os.path.join(val_images_path, os.path.basename(img_path)))\n",
    "        label_path = os.path.join(val_labels_path, os.path.splitext(os.path.basename(img_path))[0] + '.txt')\n",
    "        with open(label_path, 'w') as f:\n",
    "            f.write('0 0.5 0.5 0.2 0.2')  # Example, replace with real annotations\n",
    "\n",
    "# Split the dataset\n",
    "split_dataset(normal_path, potholes_path)\n",
    "\n",
    "# Create dataset.yaml with absolute paths\n",
    "dataset_yaml = '''\n",
    "train: {train_images_path}\n",
    "val: {val_images_path}\n",
    "nc: 1  # Number of classes (1 for potholes)\n",
    "names: ['pothole']  # Class names\n",
    "'''\n",
    "\n",
    "# Write dataset.yaml to file with absolute paths\n",
    "with open('dataset.yaml', 'w') as f:\n",
    "    f.write(dataset_yaml.format(train_images_path=train_images_path.replace('\\\\', '/'), \n",
    "                               val_images_path=val_images_path.replace('\\\\', '/')))\n",
    "\n",
    "# Update Ultralytics settings to use the correct dataset directory (optional)\n",
    "settings_path = os.path.join(os.path.expanduser('~'), 'AppData', 'Roaming', 'Ultralytics', 'settings.json')\n",
    "if os.path.exists(settings_path):\n",
    "    import json\n",
    "    with open(settings_path, 'r') as f:\n",
    "        settings = json.load(f)\n",
    "    settings['datasets_dir'] = base_path  # Update to your pothole_image_data directory\n",
    "    with open(settings_path, 'w') as f:\n",
    "        json.dump(settings, f, indent=4)\n",
    "else:\n",
    "    print(f\"Settings file not found at {settings_path}. Using default dataset directory.\")\n",
    "\n",
    "# Load or train a custom YOLOv8 model\n",
    "model = YOLO('yolov8n.pt')  # Start with pre-trained YOLOv8 nano model\n",
    "\n",
    "# Train the model on your pothole dataset\n",
    "model.train(\n",
    "    data='dataset.yaml',\n",
    "    epochs=100,  # Increase for better accuracy, adjust as needed\n",
    "    imgsz=640,   # Image size, adjust based on your images (YOLOv8 default is 640)\n",
    "    batch=16,    # Batch size, adjust based on your GPU/CPU memory\n",
    "    project='runs/train',  # Output directory for training results\n",
    "    name='pothole_detection',  # Experiment name\n",
    "    exist_ok=True  # Allow overwriting existing runs\n",
    ")\n",
    "\n",
    "# Load the best trained model\n",
    "best_model = YOLO('runs/train/pothole_detection/weights/best.pt')  # Path to best model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Error: Could not load image at {image_path}\")\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply bilateral filtering for noise reduction and edge preservation\n",
    "    smoothed = cv2.bilateralFilter(gray, 9, 75, 75)  # d=9, sigmaColor=75, sigmaSpace=75\n",
    "    \n",
    "    # Enhance contrast with CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    enhanced = clahe.apply(smoothed)\n",
    "    \n",
    "    # Use Canny edge detection with adaptive thresholding\n",
    "    edges = cv2.Canny(enhanced, 50, 150)  # Adjust thresholds as needed\n",
    "    \n",
    "    # Morphological operations to clean edges\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    edges = cv2.dilate(edges, kernel, iterations=1)\n",
    "    edges = cv2.erode(edges, kernel, iterations=1)\n",
    "    \n",
    "    return image, edges\n",
    "\n",
    "def get_grid_position(width, height, center_x, center_y, grid_size=10):\n",
    "    # Divide the image into a grid_size x grid_size grid\n",
    "    grid_width = width // grid_size\n",
    "    grid_height = height // grid_size\n",
    "    \n",
    "    # Calculate grid cell (row, column) based on center coordinates\n",
    "    row = center_y // grid_height\n",
    "    col = center_x // grid_width\n",
    "    \n",
    "    # Ensure row and col are within bounds\n",
    "    row = min(max(0, row), grid_size - 1)\n",
    "    col = min(max(0, col), grid_size - 1)\n",
    "    \n",
    "    return row, col\n",
    "\n",
    "def detect_pothole_in_image(model, image_path, scale_factor=0.1, grid_size=10):\n",
    "    # Preprocess the image\n",
    "    original_image, edges = preprocess_image(image_path)\n",
    "    \n",
    "    # Load and predict with YOLOv8\n",
    "    results = model(image_path, conf=0.5)  # Confidence threshold of 0.5\n",
    "    \n",
    "    # Convert BGR to RGB for display\n",
    "    rgb_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    pothole_detected = False\n",
    "    image_width, image_height = rgb_image.shape[1], rgb_image.shape[0]\n",
    "    \n",
    "    for result in results:\n",
    "        boxes = result.boxes  # Get bounding boxes\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)  # Convert to CPU and int\n",
    "            conf = box.conf.cpu().numpy()[0]  # Confidence score\n",
    "            \n",
    "            if conf >= 0.5:  # Ensure confidence threshold\n",
    "                pothole_detected = True\n",
    "                print(f\"Pothole Detected with confidence {conf:.2f}!\")\n",
    "                \n",
    "                # Calculate width and height in pixels\n",
    "                w = x2 - x1\n",
    "                h = y2 - y1\n",
    "                \n",
    "                # Calculate dimensions in cm (adjust scale_factor based on image resolution and real-world distance)\n",
    "                width_cm = w * scale_factor\n",
    "                height_cm = h * scale_factor\n",
    "                \n",
    "                # Calculate position (center coordinates in pixels)\n",
    "                center_x = (x1 + x2) // 2\n",
    "                center_y = (y1 + y2) // 2\n",
    "                \n",
    "                # Get grid position (row, column) in a 10x10 grid\n",
    "                grid_row, grid_col = get_grid_position(image_width, image_height, center_x, center_y, grid_size)\n",
    "                \n",
    "                # Draw bounding box and text\n",
    "                cv2.rectangle(rgb_image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                text = f'Pothole: {width_cm:.2f}cm x {height_cm:.2f}cm\\nGrid Position: Row {grid_row}, Col {grid_col}'\n",
    "                cv2.putText(rgb_image, text, (x1, y1-10), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "    \n",
    "    if not pothole_detected:\n",
    "        print(\"No Pothole Detected.\")\n",
    "        cv2.putText(rgb_image, 'No Pothole', (50, 50),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "    \n",
    "    # Display the result\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(rgb_image)\n",
    "    plt.title('Pothole Detection Result')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    # Optionally save the annotated image\n",
    "    output_path = 'pothole_detection_result.jpg'\n",
    "    cv2.imwrite(output_path, cv2.cvtColor(rgb_image, cv2.COLOR_RGB2BGR))\n",
    "    print(f\"Annotated image saved as {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_potholes_in_video(model, video_path, output_path='pothole_detection_output.avi', scale_factor=0.1, grid_size=10):\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video file at {video_path}\")\n",
    "        return\n",
    "    \n",
    "    # Get video properties\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    \n",
    "    # Define the codec and create VideoWriter object to save the output video\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')  # You can use 'MJPG' or other codecs\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "    \n",
    "    frame_count = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break  # End of video\n",
    "        \n",
    "        frame_count += 1\n",
    "        print(f\"Processing frame {frame_count}\")\n",
    "        \n",
    "        # Preprocess the frame\n",
    "        processed_frame = preprocess_image_with_edges(frame)\n",
    "        input_frame = processed_frame.reshape(1, 128, 128, 1) / 255.0\n",
    "        \n",
    "        # Predict if a pothole is present\n",
    "        results = model(frame, conf=0.5)  # YOLOv8 prediction on the frame\n",
    "        \n",
    "        # Convert BGR frame to RGB for display and processing\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        pothole_detected = False\n",
    "        \n",
    "        for result in results:\n",
    "            boxes = result.boxes  # Get bounding boxes\n",
    "            for box in boxes:\n",
    "                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)\n",
    "                conf = box.conf.cpu().numpy()[0]\n",
    "                \n",
    "                if conf >= 0.5:\n",
    "                    pothole_detected = True\n",
    "                    print(f\"Frame {frame_count}: Pothole Detected with confidence {conf:.2f}!\")\n",
    "                    \n",
    "                    # Calculate width and height in pixels\n",
    "                    w = x2 - x1\n",
    "                    h = y2 - y1\n",
    "                    \n",
    "                    # Calculate dimensions in cm\n",
    "                    width_cm = w * scale_factor\n",
    "                    height_cm = h * scale_factor\n",
    "                    \n",
    "                    # Calculate position (center coordinates in pixels)\n",
    "                    center_x = (x1 + x2) // 2\n",
    "                    center_y = (y1 + y2) // 2\n",
    "                    \n",
    "                    # Get grid position (row, column) in a 10x10 grid\n",
    "                    grid_row, grid_col = get_grid_position(frame_width, frame_height, center_x, center_y, grid_size)\n",
    "                    \n",
    "                    # Draw bounding box and text\n",
    "                    cv2.rectangle(rgb_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                    text = f'Pothole: {width_cm:.2f}cm x {height_cm:.2f}cm\\nGrid Position: Row {grid_row}, Col {grid_col}'\n",
    "                    cv2.putText(rgb_frame, text, (x1, y1-10), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "        \n",
    "        if not pothole_detected:\n",
    "            cv2.putText(rgb_frame, 'No Pothole', (50, 50),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        \n",
    "        # Convert back to BGR for OpenCV output and writing to video\n",
    "        annotated_frame = cv2.cvtColor(rgb_frame, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Write the annotated frame to the output video\n",
    "        out.write(annotated_frame)\n",
    "    \n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(f\"Annotated video saved as {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process a single image\n",
    "image_path = 'pothole.jpg'  \n",
    "detect_pothole_in_image(best_model, image_path, scale_factor=0.1, grid_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process a video\n",
    "video_path = 'demo.mp4'  \n",
    "detect_potholes_in_video(best_model, video_path, scale_factor=0.1, grid_size=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
